
# 📜 Persian Poets GPT-2 Fine-Tuning Experiments

This project contains my initial experiments fine-tuning **GPT-2** on Persian classical poetry, aiming to create a mini language model that mimics the style of famous poets like Ferdowsi, Saadi, and Hafez.


---

## 🔧 Technologies Used

- 🤖 Hugging Face Transformers  
- 🧠 GPT-2 fine-tuning  
- 📝 Jupyter Notebook for experimentation  
- 🇮🇷 Persian poetry datasets in UTF-8 encoding  

---

## 🚀 How to Run

### 1. Install Dependencies

```bash
pip install transformers datasets jupyter torch
````

### 2. Open Notebook


### 3. Run and Modify

* The notebook contains detailed cells for dataset loading, training, and text generation
* Feel free to tweak hyperparameters and try different training steps

---

## 🎯 Purpose

* Document my first attempts at Persian poetry language modeling
* Experiment with small-scale fine-tuning of GPT-2
* Explore cultural language models in NLP


## 📜 License

MIT License — use and adapt as you wish.

---

## ✉️ Contact

Created by [Pouya Soltani](https://github.com/pouyasolltani81)
Feedback and collaboration welcome!

```

If you want, I can help you create this as a file here or help you push it to GitHub!
```
