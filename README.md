
# ğŸ“œ Persian Poets GPT-2 Fine-Tuning Experiments

This project contains my initial experiments fine-tuning **GPT-2** on Persian classical poetry, aiming to create a mini language model that mimics the style of famous poets like Ferdowsi, Saadi, and Hafez.


---

## ğŸ”§ Technologies Used

- ğŸ¤– Hugging Face Transformers  
- ğŸ§  GPT-2 fine-tuning  
- ğŸ“ Jupyter Notebook for experimentation  
- ğŸ‡®ğŸ‡· Persian poetry datasets in UTF-8 encoding  

---

## ğŸš€ How to Run

### 1. Install Dependencies

```bash
pip install transformers datasets jupyter torch
````

### 2. Open Notebook


### 3. Run and Modify

* The notebook contains detailed cells for dataset loading, training, and text generation
* Feel free to tweak hyperparameters and try different training steps

---

## ğŸ¯ Purpose

* Document my first attempts at Persian poetry language modeling
* Experiment with small-scale fine-tuning of GPT-2
* Explore cultural language models in NLP


## ğŸ“œ License

MIT License â€” use and adapt as you wish.

---

## âœ‰ï¸ Contact

Created by [Pouya Soltani](https://github.com/pouyasolltani81)
Feedback and collaboration welcome!

```

If you want, I can help you create this as a file here or help you push it to GitHub!
```
