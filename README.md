
```markdown
# 📜 Persian Poets GPT-2 Fine-Tuning Experiments

This project contains my initial experiments fine-tuning **GPT-2** on Persian classical poetry, aiming to create a mini language model that mimics the style of famous poets like Ferdowsi, Saadi, and Hafez.

---

## 📁 Project Structure

```

persian\_poets\_llms/
├── experiments.ipynb       # Single notebook documenting fine-tuning and generation experiments
├── datasets/               # Text files with poetry data and training samples
└── results/                # Text files showing generated poetry outputs

````

---

## 🔧 Technologies Used

- 🤖 Hugging Face Transformers  
- 🧠 GPT-2 fine-tuning  
- 📝 Jupyter Notebook for experimentation  
- 🇮🇷 Persian poetry datasets in UTF-8 encoding  

---

## 🚀 How to Run

### 1. Install Dependencies

```bash
pip install transformers datasets jupyter torch
````

### 2. Open Notebook

```bash
jupyter notebook experiments.ipynb
```

### 3. Run and Modify

* The notebook contains detailed cells for dataset loading, training, and text generation
* Feel free to tweak hyperparameters and try different training steps

---

## 🎯 Purpose

* Document my first attempts at Persian poetry language modeling
* Experiment with small-scale fine-tuning of GPT-2
* Explore cultural language models in NLP

---

## 🧪 Results

* Generated poetic text samples stored in the `results/` folder
* Some quality issues expected due to dataset size and training constraints

---

## 📜 License

MIT License — use and adapt as you wish.

---

## ✉️ Contact

Created by [Pouya Soltani](https://github.com/pouyasolltani81)
Feedback and collaboration welcome!

```

If you want, I can help you create this as a file here or help you push it to GitHub!
```
